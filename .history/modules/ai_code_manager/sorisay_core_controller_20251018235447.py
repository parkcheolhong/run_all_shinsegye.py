import speech_recognition as sr
import pyttsx3
import time
import json
import os
from .plugins.plugin_manager import PluginManager
from .sorisay_dashboard_web import broadcast_voice_command, broadcast_system_status
from .ai_code_manager.nlp_processor import NLPProcessor
from .ai_code_manager.self_learning_engine import SelfLearningEngine
from .ai_code_manager.auto_feature_expansion import AutoFeatureExpansion
from .ai_code_manager.creative_sorisay_engine import CreativeSorisayEngine

class SorisayCore:
    def __init__(self, config_path="config/settings.json"):
        # ì„¤ì • ë¡œë“œ
        self.config = self.load_config(config_path)
        
        # ìŒì„± ì¸ì‹ ì„¤ì •
        self.recognizer = sr.Recognizer()
        voice_config = self.config.get("voice_recognition", {})
        self.recognizer.energy_threshold = voice_config.get("energy_threshold", 300)
        self.recognizer.dynamic_energy_threshold = voice_config.get("dynamic_energy_threshold", True)
        self.recognizer.pause_threshold = voice_config.get("pause_threshold", 0.8)
        self.recognizer.phrase_threshold = voice_config.get("phrase_threshold", 0.3)
        
        # TTS ì„¤ì •
        self.engine = pyttsx3.init()
        tts_config = self.config.get("tts", {})
        self.setup_tts_voice(tts_config)
        
        # í”ŒëŸ¬ê·¸ì¸ ë§¤ë‹ˆì € ì´ˆê¸°í™”
        self.plugin_manager = PluginManager()
        self.plugin_manager.load_plugins()
        
        # ìì—°ì–´ ì²˜ë¦¬ê¸° ì´ˆê¸°í™”
        self.nlp_processor = NLPProcessor()
        
        # ìê°€ í•™ìŠµ ì—”ì§„ ì´ˆê¸°í™”
        self.learning_engine = SelfLearningEngine()
        
        # ìë™ ê¸°ëŠ¥ í™•ì¥ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self.auto_expansion = AutoFeatureExpansion()
        
        # ğŸ¨ ì°½ì¡°í˜• ì†Œë¦¬ìƒˆ ì—”ì§„ ì´ˆê¸°í™”
        self.creative_engine = CreativeSorisayEngine()
        
        # ì§„í™” ì¹´ìš´í„°
        self.interaction_count = 0
        self.last_evolution_check = 0
        
        # ğŸš€ ì°½ì¡° ëª¨ë“œ ì„¤ì • (70% í™•ë¥ ë¡œ ì°½ì¡°ì  ì•„ì´ë””ì–´ ì œì•ˆ)
        self.creative_mode = True
        self.creative_probability = 0.75  # 75% í™•ë¥ ë¡œ ì°½ì¡°ì  ì•„ì´ë””ì–´
        
        self.running = True
        
        # ëŒ€ì‹œë³´ë“œì— ì‹œìŠ¤í…œ ì‹œì‘ ì•Œë¦¼
        broadcast_system_status("ì†Œë¦¬ìƒˆ ì‹œìŠ¤í…œ ì‹œì‘ë¨")

    def load_config(self, config_path):
        """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
        try:
            if os.path.exists(config_path):
                with open(config_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            else:
                print(f"âš  ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config_path}")
                return self.get_default_config()
        except Exception as e:
            print(f"âš  ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return self.get_default_config()
    
    def get_default_config(self):
        """ê¸°ë³¸ ì„¤ì • ë°˜í™˜"""
        return {
            "voice_recognition": {
                "energy_threshold": 300,
                "dynamic_energy_threshold": True,
                "pause_threshold": 0.8,
                "phrase_threshold": 0.3,
                "timeout": 5,
                "phrase_time_limit": 3
            },
            "tts": {
                "rate": 120,  # ë” ëŠë¦¬ê²Œ (ê¸°ì¡´ 150ì—ì„œ 120ìœ¼ë¡œ)
                "voice_index": 0,
                "volume": 0.9,
                "voice_gender": "female",
                "language": "ko",
                "emotion": "friendly",
                "pitch": 0,
                "voice_effects": {
                    "enable_emotion": False,  # ê°ì • í‘œí˜„ ë¹„í™œì„±í™”
                    "enable_speed_variation": False,  # ì†ë„ ë³€í™” ë¹„í™œì„±í™”
                    "enable_pause_insertion": False  # ì¼ì‹œì •ì§€ ë¹„í™œì„±í™”
                }
            }
        }

    def setup_tts_voice(self, tts_config):
        """TTS ìŒì„± ì„¤ì •"""
        try:
            # ê¸°ë³¸ TTS ì†ì„± ì„¤ì •
            rate = tts_config.get("rate", 150)
            volume = tts_config.get("volume", 0.9)
            voice_index = tts_config.get("voice_index", 0)
            
            self.engine.setProperty('rate', rate)
            self.engine.setProperty('volume', volume)
            
            # ì‚¬ìš© ê°€ëŠ¥í•œ ìŒì„± ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            voices = self.engine.getProperty('voices')
            
            if voices:
                # í•œêµ­ì–´ ìŒì„± ì°¾ê¸° (ì„ í˜¸ë„ ìˆœ)
                korean_voices = []
                female_voices = []
                
                for i, voice in enumerate(voices):
                    voice_name = voice.name.lower()
                    voice_id = voice.id.lower()
                    
                    # í•œêµ­ì–´ ìŒì„± ìš°ì„  ì„ íƒ
                    if any(keyword in voice_name or keyword in voice_id 
                          for keyword in ['korean', 'ko-kr', 'korea', 'í•œêµ­']):
                        korean_voices.append((i, voice))
                    
                    # ì—¬ì„± ìŒì„± ìš°ì„  ì„ íƒ  
                    if any(keyword in voice_name or keyword in voice_id
                          for keyword in ['female', 'woman', 'zira', 'hazel']):
                        female_voices.append((i, voice))
                
                # ìŒì„± ì„ íƒ ìš°ì„ ìˆœìœ„: í•œêµ­ì–´ > ì—¬ì„± > ì¸ë±ìŠ¤
                selected_voice = None
                if korean_voices:
                    selected_voice = korean_voices[0]
                    print(f"ğŸ¤ í•œêµ­ì–´ ìŒì„± ì„ íƒ: {selected_voice[1].name}")
                elif female_voices:
                    selected_voice = female_voices[0]
                    print(f"ğŸ¤ ì—¬ì„± ìŒì„± ì„ íƒ: {selected_voice[1].name}")
                elif voice_index < len(voices):
                    selected_voice = (voice_index, voices[voice_index])
                    print(f"ğŸ¤ ìŒì„± ì„ íƒ: {selected_voice[1].name}")
                
                if selected_voice:
                    self.engine.setProperty('voice', selected_voice[1].id)
                
            print(f"ğŸ”Š TTS ì„¤ì • ì™„ë£Œ - ì†ë„: {rate}, ë³¼ë¥¨: {volume}")
            
        except Exception as e:
            print(f"âš  TTS ì„¤ì • ì¤‘ ì˜¤ë¥˜: {e}")

    def speak_with_emotion(self, text, emotion="neutral", speed_modifier=1.0):
        """ê°ì •ê³¼ ì†ë„ ì¡°ì ˆì´ ê°€ëŠ¥í•œ ìŒì„± ì¶œë ¥"""
        try:
            tts_config = self.config.get("tts", {})
            effects = tts_config.get("voice_effects", {})
            
            # ì›ë˜ ì†ë„ ì €ì¥
            original_rate = self.engine.getProperty('rate')
            
            # ê°ì •ì— ë”°ë¥¸ ì†ë„ ì¡°ì ˆ - ë” ìì—°ìŠ¤ëŸ½ê²Œ
            if effects.get("enable_speed_variation", True):
                emotion_rates = {
                    "excited": original_rate * 1.05,  # ì‚´ì§ë§Œ ë¹ ë¥´ê²Œ
                    "happy": original_rate * 1.02,   # ì•„ì£¼ ì‚´ì§ ë¹ ë¥´ê²Œ
                    "neutral": original_rate,
                    "sad": original_rate * 0.95,     # ì‚´ì§ ëŠë¦¬ê²Œ
                    "error": original_rate * 0.98,   # ì¡°ê¸ˆ ëŠë¦¬ê²Œ
                    "success": original_rate * 1.02, # ì‚´ì§ ë¹ ë¥´ê²Œ
                    "casual": original_rate * 0.98   # í¸ì•ˆí•˜ê²Œ ëŠë¦¬ê²Œ
                }
                new_rate = int(emotion_rates.get(emotion, original_rate) * speed_modifier)
                self.engine.setProperty('rate', new_rate)
            else:
                # ëŒ€í™” ëª¨ë“œì—ì„œëŠ” ì†ë„ ë³€í™” ìµœì†Œí™”
                new_rate = int(original_rate * speed_modifier)
                self.engine.setProperty('rate', new_rate)
            
            # ê°ì •ì— ë”°ë¥¸ í…ìŠ¤íŠ¸ ìˆ˜ì •
            if effects.get("enable_emotion", True):
                text = self.add_emotional_markers(text, emotion)
            
            # ìì—°ìŠ¤ëŸ¬ìš´ ì¼ì‹œì •ì§€ ì¶”ê°€
            if effects.get("enable_pause_insertion", True):
                text = self.add_natural_pauses(text)
            
            print(f"ğŸ—£ [{emotion}] {text}")
            self.engine.say(text)
            self.engine.runAndWait()
            
            # ì›ë˜ ì†ë„ë¡œ ë³µì›
            self.engine.setProperty('rate', original_rate)
            
        except Exception as e:
            print(f"âš  ìŒì„± ì¶œë ¥ ì˜¤ë¥˜: {e}")
            # ê¸°ë³¸ speak ë©”ì„œë“œë¡œ fallback
            self.speak(text)

    def add_emotional_markers(self, text, emotion):
        """ê°ì •ì— ë”°ë¥¸ í…ìŠ¤íŠ¸ ë§ˆì»¤ ì¶”ê°€ - ìì—°ìŠ¤ëŸ½ê²Œ"""
        emotion_prefixes = {
            "excited": "",      # ê³¼ë„í•œ í‘œí˜„ ì œê±°
            "happy": "",        # ìì—°ìŠ¤ëŸ½ê²Œ
            "success": "",      # ì°¨ë¶„í•˜ê²Œ
            "error": "ìŒ, ",    # ì¡°ê¸ˆë§Œ
            "sad": "",          # ë‹´ë‹´í•˜ê²Œ
            "neutral": "",
            "casual": ""        # í¸ì•ˆí•˜ê²Œ
        }
        
        emotion_suffixes = {
            "excited": "",      # ëŠë‚Œí‘œ ì œê±°
            "happy": "",        # ìì—°ìŠ¤ëŸ½ê²Œ
            "success": "",      # ì°¨ë¶„í•˜ê²Œ
            "error": "",        # ê°„ë‹¨í•˜ê²Œ
            "sad": "",          # ë‹´ë‹´í•˜ê²Œ
            "neutral": "",
            "casual": ""        # í¸ì•ˆí•˜ê²Œ
        }
        
        prefix = emotion_prefixes.get(emotion, "")
        suffix = emotion_suffixes.get(emotion, "")
        
        return f"{prefix}{text}{suffix}"

    def add_natural_pauses(self, text):
        """ìì—°ìŠ¤ëŸ¬ìš´ ì¼ì‹œì •ì§€ ì¶”ê°€ - ê°„ë‹¨í•˜ê²Œ"""
        # ê¸°ë³¸ í…ìŠ¤íŠ¸ ê·¸ëŒ€ë¡œ ë°˜í™˜ (ì¼ì‹œì •ì§€ ë§ˆì»¤ ì œê±°)
        return text
        
        return text

    def speak(self, text, emotion="neutral"):
        """ê°œì„ ëœ ìŒì„± ì¶œë ¥ (ê°ì • ì§€ì›)"""
        self.speak_with_emotion(text, emotion)

    def listen(self):
        try:
            voice_config = self.config.get("voice_recognition", {})
            with sr.Microphone() as source:
                print("ğŸ§ ë“£ëŠ” ì¤‘...")
                self.recognizer.adjust_for_ambient_noise(
                    source, 
                    duration=voice_config.get("ambient_noise_duration", 0.5)
                )
                audio = self.recognizer.listen(
                    source, 
                    timeout=voice_config.get("timeout", 5), 
                    phrase_time_limit=voice_config.get("phrase_time_limit", 3)
                )
                
                cmd = self.recognizer.recognize_google(audio, language="ko-KR")
                print(f"ğŸ™ ì¸ì‹ëœ ëª…ë ¹: '{cmd}'")
                return cmd.strip()
                
        except sr.WaitTimeoutError:
            print("â± ìŒì„± ì…ë ¥ ëŒ€ê¸° ì‹œê°„ ì´ˆê³¼")
            return None
        except sr.UnknownValueError:
            print("âš  ìŒì„±ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤")
            self.speak("ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì„¸ìš”")
            return None
        except sr.RequestError as e:
            print(f"ğŸš« Google Speech Recognition ì˜¤ë¥˜: {e}")
            self.speak("ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”")
            return None

    def run(self):
        self.speak("ì§„í™”í˜• ì†Œë¦¬ìƒˆê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤. ì €ëŠ” ìŠ¤ìŠ¤ë¡œ í•™ìŠµí•˜ê³  ë°œì „í•©ë‹ˆë‹¤.")
        
        # í•™ìŠµ í˜„í™© ì¶œë ¥
        learning_summary = self.learning_engine.get_learning_summary()
        print(f"ğŸ“š í•™ìŠµ í˜„í™©: {learning_summary}")
        
        # ëª¨ë“  í”ŒëŸ¬ê·¸ì¸ì˜ ë„ì›€ë§ ì¶œë ¥
        help_text = self.plugin_manager.get_all_help()
        print(help_text)
        print("-" * 50)
        
        broadcast_system_status("ì§„í™”í˜• AI ëŒ€ê¸° ì¤‘")
        
        while self.running:
            cmd = self.listen()
            if not cmd: 
                time.sleep(0.5)
                continue
            
            self.interaction_count += 1
            response_success = False
            final_response = ""
            
            # ğŸ§  ìê°€ í•™ìŠµëœ ì§€ì‹ìœ¼ë¡œ ë¨¼ì € ì‘ë‹µ ì‹œë„
            smart_response = self.learning_engine.smart_response(cmd)
            if smart_response:
                print(f"ğŸ“ í•™ìŠµëœ ì§€ì‹ìœ¼ë¡œ ì‘ë‹µ: {smart_response[:50]}...")
                self.speak(smart_response)
                final_response = smart_response
                response_success = True
                broadcast_voice_command(cmd, "smart_success")
                
                # í•™ìŠµ ê¸°ë¡
                self.learning_engine.learn_from_interaction(cmd, smart_response, True)
                yield cmd
                
            else:
                # ê¸°ì¡´ NLP ì²˜ë¦¬
                nlp_result = self.nlp_processor.process_natural_language(cmd)
                intent = nlp_result["intent"]
                confidence = nlp_result["confidence"]
                
                print(f"ğŸ§  NLP ë¶„ì„: ì˜ë„='{intent}', ì‹ ë¢°ë„={confidence:.2f}")
                
                # ë†’ì€ ì‹ ë¢°ë„ë¡œ ì˜ë„ê°€ íŒŒì•…ëœ ê²½ìš°
                if intent and confidence > 0.5:
                    mapped_command = self.nlp_processor.get_command_mapping(intent)
                    emotion = nlp_result.get("emotion", "neutral")
                    
                    if mapped_command:
                        plugin_name, command, keyword = self.plugin_manager.find_command(mapped_command)
                        
                        if plugin_name and command:
                            print(f"âœ… ìì—°ì–´ ëª…ë ¹ ì‹¤í–‰: '{cmd}' -> '{mapped_command}' (í”ŒëŸ¬ê·¸ì¸: {plugin_name})")
                            broadcast_voice_command(cmd, "success")
                            
                            nlp_response = nlp_result["response"]
                            self.speak(nlp_response, emotion)
                            
                            try:
                                response = self.plugin_manager.execute_command(plugin_name, command, cmd)
                                if response != nlp_response:
                                    self.speak(response, "success")
                                
                                final_response = f"{nlp_response} {response}"
                                response_success = True
                                
                                if command == "stop":
                                    self.running = False
                                    broadcast_system_status("ì‹œìŠ¤í…œ ì¢…ë£Œ ì¤‘")
                                    
                            except Exception as e:
                                error_msg = f"ëª…ë ¹ì–´ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
                                print(f"âŒ {error_msg}")
                                self.speak(error_msg, "error")
                                final_response = error_msg
                                broadcast_voice_command(cmd, "failed")
                                
                            yield cmd
                        else:
                            print(f"âœ… ìì—°ì–´ ì‘ë‹µ: '{intent}'")
                            response_text = nlp_result["response"]
                            self.speak(response_text, emotion)
                            final_response = response_text
                            response_success = True
                            broadcast_voice_command(cmd, "success")
                            yield cmd
                    else:
                        print(f"âš  ë§¤í•‘ë˜ì§€ ì•Šì€ ì˜ë„: '{intent}'")
                        response_text = nlp_result["response"]
                        self.speak(response_text, emotion)
                        final_response = response_text
                        response_success = False
                        broadcast_voice_command(cmd, "warning")
                        yield cmd
                else:
                    # ğŸŒ ì›¹ ê²€ìƒ‰ì„ í†µí•œ ìƒˆë¡œìš´ ì§€ì‹ íšë“
                    print(f"ğŸ” ì›¹ ê²€ìƒ‰ì„ í†µí•œ ì§€ì‹ í™•ì¥ ì‹œë„...")
                    search_results = self.learning_engine.web_search(cmd)
                    
                    if search_results and search_results[0].get("content"):
                        web_response = f"ì›¹ì—ì„œ ì°¾ì€ ì •ë³´ì…ë‹ˆë‹¤: {search_results[0]['content'][:200]}..."
                        self.speak(web_response)
                        final_response = web_response
                        response_success = True
                        broadcast_voice_command(cmd, "web_search_success")
                        
                        # ìƒˆë¡œìš´ ì§€ì‹ìœ¼ë¡œ í•™ìŠµ
                        self.learning_engine.learn_from_interaction(cmd, web_response, True)
                        yield cmd
                    else:
                        # ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬
                        plugin_name, command, keyword = self.plugin_manager.find_command(cmd)
                        
                        if plugin_name and command:
                            print(f"âœ… '{keyword}' ëª…ë ¹ì–´ ì‹¤í–‰ (í”ŒëŸ¬ê·¸ì¸: {plugin_name})")
                            broadcast_voice_command(cmd, "success")
                            
                            try:
                                response = self.plugin_manager.execute_command(plugin_name, command, cmd)
                                self.speak(response)
                                final_response = response
                                response_success = True
                                
                                if command == "stop":
                                    self.running = False
                                    broadcast_system_status("ì‹œìŠ¤í…œ ì¢…ë£Œ ì¤‘")
                                    
                            except Exception as e:
                                error_msg = f"ëª…ë ¹ì–´ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
                                print(f"âŒ {error_msg}")
                                self.speak(error_msg)
                                final_response = error_msg
                                broadcast_voice_command(cmd, "failed")
                                
                            yield cmd
                        else:
                            # ì™„ì „íˆ ì´í•´í•˜ì§€ ëª»í•œ ê²½ìš°
                            unknown_response = "ì£„ì†¡í•©ë‹ˆë‹¤. ì•„ì§ ì´í•´í•˜ì§€ ëª»í•˜ëŠ” ìš”ì²­ì…ë‹ˆë‹¤. í•˜ì§€ë§Œ í•™ìŠµí•´ì„œ ë‹¤ìŒì—” ë” ì˜ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
                            self.speak(unknown_response)
                            final_response = unknown_response
                            response_success = False
                            broadcast_voice_command(cmd, "learning_needed")
                            yield cmd
                
                # ëª¨ë“  ìƒí˜¸ì‘ìš©ì—ì„œ í•™ìŠµ
                if not smart_response:  # ì´ë¯¸ í•™ìŠµí•˜ì§€ ì•Šì€ ê²½ìš°ë§Œ
                    self.learning_engine.learn_from_interaction(cmd, final_response, response_success)
            
            # ğŸ¨ ì°½ì¡°ì  ì•„ì´ë””ì–´ ì œì•ˆ (75% í™•ë¥ )
            if self.creative_mode and random.random() < self.creative_probability:
                import random
                time.sleep(0.8)  # ìì—°ìŠ¤ëŸ¬ìš´ ê°„ê²©
                
                creative_ideas = [
                    self.creative_engine.generate_creative_idea(cmd),
                    self.creative_engine.suggest_improvements()[0] if self.creative_engine.suggest_improvements() else "ìƒˆë¡œìš´ ê¸°ëŠ¥ì„ ê°œë°œí•´ë³´ê² ìŠµë‹ˆë‹¤"
                ]
                
                creative_response = random.choice(creative_ideas)
                if isinstance(creative_response, dict):
                    idea_text = f"ğŸ’¡ {creative_response['name']}: {creative_response['description']}"
                else:
                    idea_text = f"ğŸ’¡ {creative_response}"
                
                print(f"ğŸ¨ ì°½ì¡°ì  ì œì•ˆ: {idea_text}")
                self.speak(idea_text)
            
            # ğŸš€ ì£¼ê¸°ì  ìê°€ ì§„í™” (30ë²ˆ ìƒí˜¸ì‘ìš©ë§ˆë‹¤ë¡œ ë” ìì£¼)
            if self.interaction_count % 30 == 0:
                evolution_msg = "ğŸ§  ìŠ¤ìŠ¤ë¡œ í•™ìŠµí•˜ì—¬ ë” ë˜‘ë˜‘í•´ì§€ê³  ìˆìŠµë‹ˆë‹¤!"
                print(evolution_msg)
                self.speak(evolution_msg)
                
            # ğŸŒŸ í•™ìŠµ í˜„í™© ê³µìœ  (100ë²ˆë§ˆë‹¤)
            if self.interaction_count % 100 == 0:
                learning_summary = self.learning_engine.get_learning_summary()
                summary_msg = f"ğŸ“š ì§€ê¸ˆê¹Œì§€ {learning_summary.get('total_interactions', 0)}ë²ˆ ëŒ€í™”í•˜ë©° í•™ìŠµí–ˆìŠµë‹ˆë‹¤!"
                print(summary_msg)
                self.speak(summary_msg)
            
            if not self.running:
                break
            time.sleep(0.5)

    def generate_creative_idea(self, context: str = "") -> str:
        """ğŸ¨ ì°½ì¡°ì  ì•„ì´ë””ì–´ ìƒì„±"""
        idea = self.creative_engine.generate_creative_idea(context)
        
        response = f"""
ğŸ¨ ìƒˆë¡œìš´ ì•„ì´ë””ì–´ê°€ ë– ì˜¬ëìŠµë‹ˆë‹¤!

ğŸ’¡ {idea['name']}
ğŸ“ {idea['description']}
â­ ì°½ì¡°ì„± ì ìˆ˜: {idea['creativity_score']}/10

ì´ ê¸°ëŠ¥ì„ ë§Œë“¤ì–´ë³¼ê¹Œìš”?
        """.strip()
        
        return response
    
    def implement_creative_feature(self, idea_name: str) -> str:
        """ğŸ› ï¸ ì°½ì¡°ì  ê¸°ëŠ¥ êµ¬í˜„"""
        idea = self.creative_engine.generate_creative_idea()
        result = self.creative_engine.implement_feature(idea)
        evolution_msg = self.creative_engine.evolve_creativity()
        return f"{result}\n\nğŸ§  {evolution_msg}"
    
    def suggest_self_improvements(self) -> str:
        """ğŸš€ ìê°€ ê°œì„  ì œì•ˆ"""
        suggestions = self.creative_engine.suggest_improvements()
        response = "ğŸš€ ìŠ¤ìŠ¤ë¡œ ìƒê°í•´ë³¸ ê°œì„  ì•„ì´ë””ì–´:\n\n"
        for i, suggestion in enumerate(suggestions, 1):
            response += f"{i}. {suggestion}\n"
        response += "\nì–´ë–¤ ê²ƒë¶€í„° ê°œì„ í•´ë³¼ê¹Œìš”?"
        return response
