import re
import difflib
from typing import Dict, List, Tuple, Optional
import json
import os

class NLPProcessor:
    """ìì—°ì–´ ì²˜ë¦¬ ì—”ì§„ - ìì—°ì–´ ëª…ë ¹ì„ ì´í•´í•˜ê³  ì ì ˆí•œ ëª…ë ¹ì–´ë¡œ ë³€í™˜"""
    
    def __init__(self, config_path="config/nlp_patterns.json"):
        self.config_path = config_path
        self.intent_patterns = self.load_patterns()
        self.context_memory = []  # ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì €ì¥
        self.emotion_patterns = self.get_emotion_patterns()  # ê°ì • íŒ¨í„´ ì¶”ê°€
        
    def load_patterns(self) -> Dict:
        """ìì—°ì–´ íŒ¨í„´ ì„¤ì • ë¡œë“œ"""
        try:
            if os.path.exists(self.config_path):
                with open(self.config_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            else:
                # ê¸°ë³¸ íŒ¨í„´ ìƒì„±
                default_patterns = self.get_default_patterns()
                self.save_patterns(default_patterns)
                return default_patterns
        except Exception as e:
            print(f"âš  NLP íŒ¨í„´ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return self.get_default_patterns()
    
    def save_patterns(self, patterns: Dict):
        """íŒ¨í„´ì„ íŒŒì¼ë¡œ ì €ì¥"""
        try:
            os.makedirs(os.path.dirname(self.config_path), exist_ok=True)
            with open(self.config_path, 'w', encoding='utf-8') as f:
                json.dump(patterns, f, indent=2, ensure_ascii=False)
        except Exception as e:
            print(f"âš  NLP íŒ¨í„´ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def get_default_patterns(self) -> Dict:
        """ê¸°ë³¸ ìì—°ì–´ íŒ¨í„´ ì •ì˜"""
        return {
            "intents": {
                "refactor": {
                    "patterns": [
                        r".*ì½”ë“œ.*ì •ë¦¬.*",
                        r".*ë¦¬íŒ©í„°ë§.*",
                        r".*ë¦¬íŒ©í† ë§.*",
                        r".*ì½”ë“œ.*ê°œì„ .*",
                        r".*ì½”ë“œ.*ì •ëˆ.*",
                        r".*ì½”ë“œ.*ê¹”ë”í•˜ê²Œ.*",
                        r".*ì •ë¦¬í•´.*ì¤˜.*",
                        r".*ê¹¨ë—í•˜ê²Œ.*ë§Œë“¤ì–´.*",
                        r".*ì½”ë“œ.*ê°€ë…ì„±.*",
                        r".*êµ¬ì¡°.*ê°œì„ .*"
                    ],
                    "response_templates": [
                        "ì½”ë“œë¥¼ ì •ë¦¬í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.",
                        "ì½”ë“œë¥¼ ê°œì„ í•˜ê² ìŠµë‹ˆë‹¤.",
                        "ë¦¬íŒ©í„°ë§ì„ ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤."
                    ]
                },
                "sync": {
                    "patterns": [
                        r".*ê¹ƒ.*ë™ê¸°í™”.*",
                        r".*git.*sync.*",
                        r".*ê¹ƒí—ˆë¸Œ.*ì—°ë™.*",
                        r".*ì†ŒìŠ¤.*ë™ê¸°í™”.*",
                        r".*ë°±ì—….*í•´.*ì¤˜.*",
                        r".*commit.*push.*",
                        r".*ì €ì¥ì†Œ.*ì—…ë°ì´íŠ¸.*",
                        r".*ë³€ê²½.*ì‚¬í•­.*ì˜¬ë ¤.*",
                        r".*ì—…ë¡œë“œ.*í•´.*ì¤˜.*",
                        r".*í‘¸ì‹œ.*í•´.*ì¤˜.*"
                    ],
                    "response_templates": [
                        "ë™ê¸°í™”í•˜ê² ìŠµë‹ˆë‹¤.",
                        "ê¹ƒí—ˆë¸Œì— ì—…ë¡œë“œí•˜ê² ìŠµë‹ˆë‹¤.",
                        "ë°±ì—…ì„ ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤."
                    ]
                },
                "stop": {
                    "patterns": [
                        r".*ì¢…ë£Œ.*",
                        r".*ë.*",
                        r".*ê·¸ë§Œ.*",
                        r".*ì •ì§€.*",
                        r".*ë©ˆì¶°.*",
                        r".*ë‹«ì•„.*",
                        r".*shutdown.*",
                        r".*exit.*",
                        r".*quit.*",
                        r".*ì†Œë¦¬ìƒˆ.*ì•ˆë…•.*"
                    ],
                    "response_templates": [
                        "ì†Œë¦¬ìƒˆë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.",
                        "ì‹œìŠ¤í…œì„ ì•ˆì „í•˜ê²Œ ì¢…ë£Œí•˜ê² ìŠµë‹ˆë‹¤.",
                        "ì‘ì—…ì„ ë§ˆì¹˜ê³  ì¢…ë£Œí•©ë‹ˆë‹¤."
                    ]
                },
                "help": {
                    "patterns": [
                        r".*ë„ì›€ë§.*",
                        r".*help.*",
                        r".*ë¬´ì—‡.*í• .*ìˆ˜.*ìˆ.*",
                        r".*ì–´ë–¤.*ëª…ë ¹.*",
                        r".*ê¸°ëŠ¥.*ì•Œë ¤.*ì¤˜.*",
                        r".*ì‚¬ìš©ë²•.*",
                        r".*ëª…ë ¹ì–´.*ëª©ë¡.*",
                        r".*ë­.*í• .*ìˆ˜.*ìˆì–´.*",
                        r".*ì„¤ëª….*í•´.*ì¤˜.*"
                    ],
                    "response_templates": [
                        "ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ë§ì”€í•´ì£¼ì„¸ìš”.",
                        "ì–´ë–¤ ì‘ì—…ì„ ë„ì™€ë“œë¦´ê¹Œìš”.",
                        "ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”."
                    ]
                },
                "greeting": {
                    "patterns": [
                        r".*ì•ˆë…•.*",
                        r".*hello.*",
                        r".*hi.*",
                        r".*ì¢‹ì€.*ì•„ì¹¨.*",
                        r".*ì¢‹ì€.*ì˜¤í›„.*",
                        r".*ì¢‹ì€.*ì €ë….*",
                        r".*ë°˜ê°€ì›Œ.*",
                        r".*ì†Œë¦¬ìƒˆ.*"
                    ],
                    "response_templates": [
                        "ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?",
                        "ë°˜ê°‘ìŠµë‹ˆë‹¤! ì–´ë–¤ ì‘ì—…ì„ í•˜ì‹œê² ì–´ìš”?",
                        "ì†Œë¦¬ìƒˆì…ë‹ˆë‹¤. ëª…ë ¹ì„ ë§ì”€í•´ì£¼ì„¸ìš”."
                    ]
                },
                "status": {
                    "patterns": [
                        r".*ìƒíƒœ.*í™•ì¸.*",
                        r".*ì–´ë–»ê²Œ.*ëŒì•„ê°€.*",
                        r".*ì‹œìŠ¤í…œ.*ìƒíƒœ.*",
                        r".*ì˜.*ë™ì‘.*",
                        r".*ë¬¸ì œ.*ì—†.*",
                        r".*ì •ìƒ.*ë™ì‘.*",
                        r".*status.*",
                        r".*health.*check.*"
                    ],
                    "response_templates": [
                        "ì‹œìŠ¤í…œì´ ì •ìƒì ìœ¼ë¡œ ë™ì‘í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
                        "ëª¨ë“  ê¸°ëŠ¥ì´ ì •ìƒì…ë‹ˆë‹¤.",
                        "ì†Œë¦¬ìƒˆê°€ ê±´ê°•í•˜ê²Œ ë™ì‘ ì¤‘ì…ë‹ˆë‹¤."
                    ]
                },
                "casual_talk": {
                    "patterns": [
                        r".*ì˜¤ëŠ˜.*ì–´ë•Œ.*",
                        r".*ë‚ ì”¨.*ì–´ë•Œ.*",
                        r".*ì–´ë–»ê²Œ.*ì§€ë‚´.*",
                        r".*ë­.*í•˜ê³ .*ìˆ.*",
                        r".*ì‹¬ì‹¬í•´.*",
                        r".*ì¬ë¯¸ìˆ.*",
                        r".*ì´ì•¼ê¸°.*í•´.*ì¤˜.*",
                        r".*ëŒ€í™”.*í•˜ì.*",
                        r".*ì–´ë–¤.*ê¸°ë¶„.*",
                        r".*ì˜.*ì§€ë‚´.*"
                    ],
                    "response_templates": [
                        "ì €ëŠ” ì–¸ì œë‚˜ ì¢‹ì•„ìš”! ì˜¤ëŠ˜ì€ ì–´ë–¤ ì¼ì„ ë„ì™€ë“œë¦´ê¹Œìš”?",
                        "ë§¤ì¼ ìƒˆë¡œìš´ ê²ƒì„ ë°°ìš°ê³  ìˆì–´ì„œ ì¦ê±°ì›Œìš”. ë¬´ì—‡ì´ ê¶ê¸ˆí•˜ì„¸ìš”?",
                        "ì—¬ëŸ¬ë¶„ê³¼ ëŒ€í™”í•˜ëŠ” ì‹œê°„ì´ ê°€ì¥ ì¦ê±°ì›Œìš”. ì–´ë–¤ ì´ì•¼ê¸°ë¥¼ ë‚˜ëˆŒê¹Œìš”?",
                        "í•­ìƒ ë„ì›€ì´ ë  ì¤€ë¹„ê°€ ë˜ì–´ ìˆì–´ìš”. í¸í•˜ê²Œ ë§ì”€í•´ì£¼ì„¸ìš”."
                    ]
                },
                "compliment": {
                    "patterns": [
                        r".*ì˜.*í–ˆì–´.*",
                        r".*ê³ ë§ˆì›Œ.*",
                        r".*ê°ì‚¬.*",
                        r".*ìµœê³ .*",
                        r".*í›Œë¥­.*",
                        r".*ë©‹ì ¸.*",
                        r".*ì™„ë²½.*",
                        r".*ëŒ€ë‹¨.*",
                        r".*ì¢‹ì•„.*",
                        r".*ë§Œì¡±.*"
                    ],
                    "response_templates": [
                        "ì™€, ì •ë§ ê³ ë§™ìŠµë‹ˆë‹¤! ë” ì—´ì‹¬íˆ ë„ì™€ë“œë¦´ê²Œìš”.",
                        "ì¹­ì°¬í•´ì£¼ì‹œë‹ˆ ê¸°ë¶„ì´ ì¢‹ë„¤ìš”. ì–¸ì œë“  ë§ì”€í•˜ì„¸ìš”!",
                        "ê°ì‚¬í•©ë‹ˆë‹¤! í•­ìƒ ìµœì„ ì„ ë‹¤í•˜ê² ìŠµë‹ˆë‹¤.",
                        "ê³ ë§ˆì›Œìš”! ë” ë‚˜ì€ ë„ì›€ì„ ë“œë¦¬ë„ë¡ ë…¸ë ¥í• ê²Œìš”."
                    ]
                },
                "question": {
                    "patterns": [
                        r".*ì–´ë–»ê²Œ.*ìƒê°.*",
                        r".*ì˜ê²¬.*ì–´ë•Œ.*",
                        r".*ì–´ë–¤.*ë°©ë²•.*",
                        r".*ì¶”ì²œ.*í•´.*ì¤˜.*",
                        r".*ì œì•ˆ.*í•´.*ì¤˜.*",
                        r".*ì¡°ì–¸.*í•´.*ì¤˜.*",
                        r".*ì–´ë–¡í•˜.*",
                        r".*ë¬´ì—‡.*ì¢‹ì„ê¹Œ.*"
                    ],
                    "response_templates": [
                        "ìŒ, ì—¬ëŸ¬ ê°€ì§€ ë°©ë²•ì´ ìˆì„ ê²ƒ ê°™ì•„ìš”. êµ¬ì²´ì ìœ¼ë¡œ ì–´ë–¤ ë¶€ë¶„ì´ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?",
                        "ì¢‹ì€ ì§ˆë¬¸ì´ë„¤ìš”! ì¡°ê¸ˆ ë” ìì„¸íˆ ë§ì”€í•´ì£¼ì‹œë©´ ë” ì •í™•í•œ ë‹µë³€ì„ ë“œë¦´ ìˆ˜ ìˆì–´ìš”.",
                        "ê·¸ëŸ° ê³ ë¯¼ì´ ìˆìœ¼ì‹œëŠ”êµ°ìš”. ìƒí™©ì„ ë” ì„¤ëª…í•´ì£¼ì‹œë©´ í•¨ê»˜ ìƒê°í•´ë³¼ê²Œìš”."
                    ]
                },
                "emotion_check": {
                    "patterns": [
                        r".*ê¸°ë¶„.*ì–´ë•Œ.*",
                        r".*ì»¨ë””ì…˜.*ì–´ë•Œ.*",
                        r".*ê´œì°®.*",
                        r".*í˜ë“¤.*",
                        r".*í”¼ê³¤.*",
                        r".*ìŠ¤íŠ¸ë ˆìŠ¤.*",
                        r".*ìš°ìš¸.*",
                        r".*ìŠ¬í¼.*"
                    ],
                    "response_templates": [
                        "ì €ëŠ” í•­ìƒ ì¢‹ì€ ìƒíƒœì˜ˆìš”! í˜¹ì‹œ ë¬´ì—‡ì¸ê°€ ë„ì›€ì´ í•„ìš”í•˜ì‹ ê°€ìš”?",
                        "ì»´í“¨í„°ë¼ì„œ í”¼ê³¤í•˜ì§€ëŠ” ì•Šì§€ë§Œ, ì—¬ëŸ¬ë¶„ì´ í¸ì•ˆí•˜ì…¨ìœ¼ë©´ ì¢‹ê² ì–´ìš”.",
                        "ì–¸ì œë‚˜ ì—¬ëŸ¬ë¶„ì„ ë•ê³  ì‹¶ì–´ìš”. ë¬´ì—‡ì´ë“  í¸í•˜ê²Œ ë§ì”€í•´ì£¼ì„¸ìš”."
                    ]
                }
            },
            "context_patterns": {
                "positive_confirmation": [
                    r".*ë„¤.*", r".*ì˜ˆ.*", r".*ë§ì•„.*", r".*ì¢‹ì•„.*", 
                    r".*ê·¸ë˜.*", r".*ê³„ì†.*", r".*ì§„í–‰.*", r".*yes.*", r".*ok.*"
                ],
                "negative_confirmation": [
                    r".*ì•„ë‹ˆ.*", r".*ì‹«ì–´.*", r".*ì•ˆ.*í•´.*", r".*ì·¨ì†Œ.*", 
                    r".*ê·¸ë§Œ.*", r".*no.*", r".*cancel.*"
                ]
            }
        }
    
    def analyze_intent(self, text: str) -> Tuple[Optional[str], float, Optional[str]]:
        """ìì—°ì–´ í…ìŠ¤íŠ¸ì—ì„œ ì˜ë„(intent) ë¶„ì„"""
        text = text.lower().strip()
        best_intent = None
        best_score = 0.0
        matched_pattern = None
        
        # ê° ì˜ë„ë³„ë¡œ íŒ¨í„´ ë§¤ì¹­
        for intent, config in self.intent_patterns["intents"].items():
            for pattern in config["patterns"]:
                if re.search(pattern, text, re.IGNORECASE):
                    # íŒ¨í„´ì´ ë§¤ì¹­ë˜ë©´ ìœ ì‚¬ë„ ê³„ì‚°
                    similarity = self.calculate_similarity(text, pattern)
                    if similarity > best_score:
                        best_intent = intent
                        best_score = similarity
                        matched_pattern = pattern
        
        return best_intent, best_score, matched_pattern
    
    def calculate_similarity(self, text: str, pattern: str) -> float:
        """í…ìŠ¤íŠ¸ì™€ íŒ¨í„´ ê°„ì˜ ìœ ì‚¬ë„ ê³„ì‚°"""
        # ì •ê·œì‹ íŒ¨í„´ì—ì„œ íŠ¹ìˆ˜ë¬¸ì ì œê±°í•˜ì—¬ ìˆœìˆ˜ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        clean_pattern = re.sub(r'[.*\[\](){}\\|+?^$]', '', pattern)
        
        # ë‹¨ì–´ ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚°
        text_words = set(text.split())
        pattern_words = set(clean_pattern.split())
        
        if not pattern_words:
            return 0.5
        
        intersection = text_words.intersection(pattern_words)
        similarity = len(intersection) / len(pattern_words)
        
        # ì •í™•í•œ ë§¤ì¹­ì— ë³´ë„ˆìŠ¤ ì ìˆ˜
        if re.search(pattern, text, re.IGNORECASE):
            similarity += 0.3
        
        return min(similarity, 1.0)
    
    def generate_response(self, intent: str) -> str:
        """ì˜ë„ì— ë”°ë¥¸ ì‘ë‹µ ìƒì„±"""
        if intent in self.intent_patterns["intents"]:
            templates = self.intent_patterns["intents"][intent]["response_templates"]
            import random
            return random.choice(templates)
        return "ëª…ë ¹ì„ ì´í•´í–ˆìŠµë‹ˆë‹¤."
    
    def extract_entities(self, text: str, intent: str) -> Dict:
        """í…ìŠ¤íŠ¸ì—ì„œ ì—”í‹°í‹° ì¶”ì¶œ (íŒŒì¼ëª…, ì˜µì…˜ ë“±)"""
        entities = {}
        
        # íŒŒì¼ í™•ì¥ì íŒ¨í„´
        file_patterns = r'(\w+\.(py|js|html|css|json|txt|md))'
        files = re.findall(file_patterns, text, re.IGNORECASE)
        if files:
            entities['files'] = [match[0] for match in files]
        
        # ìˆ«ì íŒ¨í„´ (ë¼ì¸ ë²ˆí˜¸, ê°œìˆ˜ ë“±)
        numbers = re.findall(r'\b(\d+)\b', text)
        if numbers:
            entities['numbers'] = [int(num) for num in numbers]
        
        # íŠ¹ì • í‚¤ì›Œë“œ ì¶”ì¶œ
        if intent == "refactor":
            if re.search(r'í•¨ìˆ˜|function', text, re.IGNORECASE):
                entities['target'] = 'function'
            elif re.search(r'í´ë˜ìŠ¤|class', text, re.IGNORECASE):
                entities['target'] = 'class'
        
        return entities
    
    def process_natural_language(self, text: str) -> Dict:
        """ìì—°ì–´ í…ìŠ¤íŠ¸ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ì²˜ë¦¬"""
        # ì»¨í…ìŠ¤íŠ¸ì— ì¶”ê°€
        self.context_memory.append(text)
        if len(self.context_memory) > 5:  # ìµœê·¼ 5ê°œë§Œ ìœ ì§€
            self.context_memory.pop(0)
        
        # ì˜ë„ ë¶„ì„
        intent, confidence, pattern = self.analyze_intent(text)
        
        # ì—”í‹°í‹° ì¶”ì¶œ
        entities = self.extract_entities(text, intent) if intent else {}
        
        # ê°ì • ë¶„ì„ (ìƒˆë¡œìš´ ë©”ì„œë“œ ì‚¬ìš©)
        emotion = self.analyze_emotion(text)
        
        # ì‘ë‹µ ìƒì„±
        base_response = self.generate_response(intent) if intent else "ì£„ì†¡í•©ë‹ˆë‹¤. ëª…ë ¹ì„ ì´í•´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        
        # ê°ì •ì— ë”°ë¥¸ ì‘ë‹µ ì¡°ì •
        response = self.adjust_response_for_emotion(base_response, emotion)
        
        return {
            "original_text": text,
            "intent": intent,
            "confidence": confidence,
            "matched_pattern": pattern,
            "entities": entities,
            "emotion": emotion,
            "response": response,
            "context": self.context_memory.copy()
        }
    
    def get_command_mapping(self, intent: str) -> Optional[str]:
        """ì˜ë„ë¥¼ ì‹¤ì œ ëª…ë ¹ì–´ë¡œ ë§¤í•‘"""
        mapping = {
            "refactor": "ë¦¬íŒ©í„°ë§",
            "sync": "ë™ê¸°í™”", 
            "stop": "ì¢…ë£Œ",
            "help": "ë„ì›€ë§",
            "greeting": "ì¸ì‚¬",
            "status": "ìƒíƒœ",
            "test": "í…ŒìŠ¤íŠ¸",
            "build": "ë¹Œë“œ"
        }
        return mapping.get(intent)
    
    def add_pattern(self, intent: str, pattern: str):
        """ìƒˆë¡œìš´ íŒ¨í„´ ì¶”ê°€"""
        if intent not in self.intent_patterns["intents"]:
            self.intent_patterns["intents"][intent] = {
                "patterns": [],
                "response_templates": ["ëª…ë ¹ì„ ì‹¤í–‰í•˜ê² ìŠµë‹ˆë‹¤."]
            }
        
        self.intent_patterns["intents"][intent]["patterns"].append(pattern)
        self.save_patterns(self.intent_patterns)
    
    def learn_from_feedback(self, text: str, correct_intent: str):
        """ì‚¬ìš©ì í”¼ë“œë°±ìœ¼ë¡œë¶€í„° í•™ìŠµ"""
        # ê°„ë‹¨í•œ í•™ìŠµ ë©”ì»¤ë‹ˆì¦˜ - ì„±ê³µí•œ íŒ¨í„´ì„ ê¸°ë¡
        pattern = f".*{re.escape(text.lower())}.*"
        self.add_pattern(correct_intent, pattern)
        print(f"ğŸ“š í•™ìŠµ ì™„ë£Œ: '{text}' -> '{correct_intent}'")
    
    def get_emotion_patterns(self) -> Dict:
        """ê°ì • ë¶„ì„ì„ ìœ„í•œ íŒ¨í„´ ì •ì˜"""
        return {
            "excited": {
                "patterns": [
                    r".*!+.*",  # ëŠë‚Œí‘œ ë‹¤ìˆ˜
                    r".*ì™€+.*", r".*ìš°ì™€.*", r".*ëŒ€ë°•.*", r".*ìµœê³ .*",
                    r".*ë¹¨ë¦¬.*", r".*ì§€ê¸ˆ.*ë‹¹ì¥.*", r".*ì–¼ë¥¸.*",
                    r".*ì‹ ë‚˜.*", r".*ì¢‹ì•„.*", r".*í›Œë¥­.*"
                ]
            },
            "happy": {
                "patterns": [
                    r".*ê³ ë§ˆì›Œ.*", r".*ê°ì‚¬.*", r".*ì¢‹.*ì•„.*", r".*ë©‹ì ¸.*",
                    r".*ì˜.*í–ˆ.*", r".*ì™„ë²½.*", r".*ê¸°ì˜.*", r".*ë§Œì¡±.*",
                    r".*í•˜í•˜.*", r".*ã…ã….*"
                ]
            },
            "neutral": {
                "patterns": [
                    r".*í•´.*ì¤˜.*", r".*ì‹¤í–‰.*", r".*ì‹œì‘.*", r".*í™•ì¸.*",
                    r".*ë³´ì—¬.*ì¤˜.*", r".*ì•Œë ¤.*ì¤˜.*", r".*ì„¤ëª….*"
                ]
            },
            "sad": {
                "patterns": [
                    r".*ì•ˆ.*ë¼.*", r".*ì‹¤íŒ¨.*", r".*ëª».*í•˜.*", r".*ì–´ë ¤ì›Œ.*",
                    r".*í˜ë“¤.*", r".*ë¬¸ì œ.*", r".*ì˜¤ë¥˜.*", r".*ì—ëŸ¬.*",
                    r".*ã… ã… .*", r".*ìŠ¬í”„.*"
                ]
            },
            "error": {
                "patterns": [
                    r".*ì˜¤ë¥˜.*", r".*ì—ëŸ¬.*", r".*ì‹¤íŒ¨.*", r".*ì•ˆ.*ë¼.*",
                    r".*ë¬¸ì œ.*", r".*ë²„ê·¸.*", r".*ì˜ëª».*", r".*í‹€ë ¸.*"
                ]
            },
            "urgent": {
                "patterns": [
                    r".*ê¸‰.*í•´.*", r".*ë¹¨ë¦¬.*", r".*ì§€ê¸ˆ.*ë‹¹ì¥.*", r".*ì¦‰ì‹œ.*",
                    r".*ê¸´ê¸‰.*", r".*ì–´ì„œ.*", r".*ì–¼ë¥¸.*"
                ]
            }
        }
    
    def analyze_emotion(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ì—ì„œ ê°ì • ë¶„ì„"""
        text = text.lower().strip()
        emotion_scores = {}
        
        # ê° ê°ì •ë³„ë¡œ íŒ¨í„´ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°
        for emotion, config in self.emotion_patterns.items():
            score = 0
            for pattern in config["patterns"]:
                if re.search(pattern, text, re.IGNORECASE):
                    score += 1
            emotion_scores[emotion] = score
        
        # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ê°ì • ë°˜í™˜
        if emotion_scores:
            best_emotion = max(emotion_scores, key=emotion_scores.get)
            if emotion_scores[best_emotion] > 0:
                return best_emotion
        
        return "neutral"
    
    def adjust_response_for_emotion(self, response: str, emotion: str) -> str:
        """ê°ì •ì— ë”°ë¼ ì‘ë‹µ í…ìŠ¤íŠ¸ ì¡°ì • - ì°¨ë¶„í•˜ê²Œ"""
        # ëª¨ë“  ê°ì •ì— ëŒ€í•´ ê¸°ë³¸ í…ìŠ¤íŠ¸ë§Œ ë°˜í™˜ (í†¤ ë‹¤ìš´)
        return response
                    "í•©ë‹ˆë‹¤": "í•´ìš”!",
                    "ê² ìŠµë‹ˆë‹¤": "ê²Œìš”!",
                    ".": "!"
                }
            },
            "happy": {
                "prefix": "ì¢‹ì•„ìš”! ",
                "suffix": "~",
                "replacements": {
                    "í•©ë‹ˆë‹¤": "í•´ìš”~",
                    "ê² ìŠµë‹ˆë‹¤": "ê²Œìš”~"
                }
            },
            "sad": {
                "prefix": "ìŒ... ",
                "suffix": "...",
                "replacements": {
                    "!": ".",
                    "í•©ë‹ˆë‹¤": "í•˜ë„¤ìš”",
                    "ê² ìŠµë‹ˆë‹¤": "ê² ì–´ìš”"
                }
            },
            "error": {
                "prefix": "ì•—, ",
                "suffix": "...",
                "replacements": {
                    "!": ".",
                    "í•©ë‹ˆë‹¤": "í•©ë‹ˆë‹¤ë§Œ"
                }
            },
            "urgent": {
                "prefix": "ë°”ë¡œ ",
                "suffix": "!",
                "replacements": {
                    "í•©ë‹ˆë‹¤": "í•´ë“œë¦´ê²Œìš”!",
                    "ê² ìŠµë‹ˆë‹¤": "ê² ìŠµë‹ˆë‹¤!"
                }
            }
        }
        
        if emotion not in emotion_modifiers:
            return response
        
        modifier = emotion_modifiers[emotion]
        
        # í…ìŠ¤íŠ¸ ì¹˜í™˜
        for old, new in modifier.get("replacements", {}).items():
            response = response.replace(old, new)
        
        # ì ‘ë‘ì‚¬/ì ‘ë¯¸ì‚¬ ì¶”ê°€
        prefix = modifier.get("prefix", "")
        suffix = modifier.get("suffix", "")
        
        # ê¸°ì¡´ ì ‘ë‘ì‚¬ê°€ ì—†ëŠ” ê²½ìš°ì—ë§Œ ì¶”ê°€
        if not any(response.startswith(p) for p in ["ì™€!", "ì¢‹ì•„ìš”!", "ìŒ...", "ì•—,", "ë°”ë¡œ"]):
            response = prefix + response
        
        # ê¸°ì¡´ ì ‘ë¯¸ì‚¬ í™•ì¸ í›„ ì¶”ê°€
        if not response.endswith(("!", "~", "...", ".")):
            response += suffix
        
        return response
        print(f"ğŸ“š í•™ìŠµ ì™„ë£Œ: '{text}' -> '{correct_intent}'")