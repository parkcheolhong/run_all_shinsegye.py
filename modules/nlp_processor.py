import re
import difflib
from typing import Dict, List, Tuple, Optional
import json
import os

class NLPProcessor:
    """ìì—°ì–´ ì²˜ë¦¬ ì—”ì§„ - ìì—°ì–´ ëª…ë ¹ì„ ì´í•´í•˜ê³  ì ì ˆí•œ ëª…ë ¹ì–´ë¡œ ë³€í™˜"""
    
    def __init__(self, config_path="config/nlp_patterns.json"):
        self.config_path = config_path
        self.intent_patterns = self.load_patterns()
        self.context_memory = []  # ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì €ì¥
        self.emotion_patterns = self.get_emotion_patterns()  # ê°ì • íŒ¨í„´ ì¶”ê°€
        
    def load_patterns(self) -> Dict:
        """ìì—°ì–´ íŒ¨í„´ ì„¤ì • ë¡œë“œ"""
        try:
            if os.path.exists(self.config_path):
                with open(self.config_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            else:
                # ê¸°ë³¸ íŒ¨í„´ ìƒì„±
                default_patterns = self.get_default_patterns()
                self.save_patterns(default_patterns)
                return default_patterns
        except Exception as e:
            print(f"âš  NLP íŒ¨í„´ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return self.get_default_patterns()
    
    def save_patterns(self, patterns: Dict):
        """íŒ¨í„´ì„ íŒŒì¼ë¡œ ì €ì¥"""
        try:
            os.makedirs(os.path.dirname(self.config_path), exist_ok=True)
            with open(self.config_path, 'w', encoding='utf-8') as f:
                json.dump(patterns, f, indent=2, ensure_ascii=False)
        except Exception as e:
            print(f"âš  NLP íŒ¨í„´ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def get_default_patterns(self) -> Dict:
        """ê¸°ë³¸ ìì—°ì–´ íŒ¨í„´ ì •ì˜"""
        return {
            "intents": {
                "refactor": {
                    "patterns": [
                        r".*ì½”ë“œ.*ì •ë¦¬.*",
                        r".*ë¦¬íŒ©í„°ë§.*",
                        r".*ë¦¬íŒ©í† ë§.*",
                        r".*ì½”ë“œ.*ê°œì„ .*",
                        r".*ì½”ë“œ.*ì •ëˆ.*",
                        r".*ì½”ë“œ.*ê¹”ë”í•˜ê²Œ.*",
                        r".*ì •ë¦¬í•´.*ì¤˜.*",
                        r".*ê¹¨ë—í•˜ê²Œ.*ë§Œë“¤ì–´.*",
                        r".*ì½”ë“œ.*ê°€ë…ì„±.*",
                        r".*êµ¬ì¡°.*ê°œì„ .*"
                    ],
                    "response_templates": [
                        "ì½”ë“œ ë¦¬íŒ©í„°ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤.",
                        "ì½”ë“œë¥¼ ì •ë¦¬í•˜ê³  ê°œì„ í•˜ê² ìŠµë‹ˆë‹¤.",
                        "ì½”ë“œ êµ¬ì¡°ë¥¼ ê°œì„ í•˜ê² ìŠµë‹ˆë‹¤."
                    ]
                },
                "sync": {
                    "patterns": [
                        r".*ê¹ƒ.*ë™ê¸°í™”.*",
                        r".*git.*sync.*",
                        r".*ê¹ƒí—ˆë¸Œ.*ì—°ë™.*",
                        r".*ì†ŒìŠ¤.*ë™ê¸°í™”.*",
                        r".*ë°±ì—….*í•´.*ì¤˜.*",
                        r".*commit.*push.*",
                        r".*ì €ì¥ì†Œ.*ì—…ë°ì´íŠ¸.*",
                        r".*ë³€ê²½.*ì‚¬í•­.*ì˜¬ë ¤.*",
                        r".*ì—…ë¡œë“œ.*í•´.*ì¤˜.*",
                        r".*í‘¸ì‹œ.*í•´.*ì¤˜.*"
                    ],
                    "response_templates": [
                        "ê¹ƒí—ˆë¸Œì™€ ë™ê¸°í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.",
                        "ì†ŒìŠ¤ ì½”ë“œë¥¼ ë™ê¸°í™”í•˜ê² ìŠµë‹ˆë‹¤.",
                        "ë³€ê²½ì‚¬í•­ì„ ê¹ƒí—ˆë¸Œì— ì—…ë¡œë“œí•˜ê² ìŠµë‹ˆë‹¤."
                    ]
                },
                "stop": {
                    "patterns": [
                        r".*ì¢…ë£Œ.*",
                        r".*ë.*",
                        r".*ê·¸ë§Œ.*",
                        r".*ì •ì§€.*",
                        r".*ë©ˆì¶°.*",
                        r".*ë‹«ì•„.*",
                        r".*shutdown.*",
                        r".*exit.*",
                        r".*quit.*",
                        r".*ì†Œë¦¬ìƒˆ.*ì•ˆë…•.*"
                    ],
                    "response_templates": [
                        "ì†Œë¦¬ìƒˆë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.",
                        "ì‹œìŠ¤í…œì„ ì•ˆì „í•˜ê²Œ ì¢…ë£Œí•˜ê² ìŠµë‹ˆë‹¤.",
                        "ì‘ì—…ì„ ë§ˆì¹˜ê³  ì¢…ë£Œí•©ë‹ˆë‹¤."
                    ]
                },
                "help": {
                    "patterns": [
                        r".*ë„ì›€ë§.*",
                        r".*help.*",
                        r".*ë¬´ì—‡.*í• .*ìˆ˜.*ìˆ.*",
                        r".*ì–´ë–¤.*ëª…ë ¹.*",
                        r".*ê¸°ëŠ¥.*ì•Œë ¤.*ì¤˜.*",
                        r".*ì‚¬ìš©ë²•.*",
                        r".*ëª…ë ¹ì–´.*ëª©ë¡.*",
                        r".*ë­.*í• .*ìˆ˜.*ìˆì–´.*",
                        r".*ì„¤ëª….*í•´.*ì¤˜.*"
                    ],
                    "response_templates": [
                        "ì†Œë¦¬ìƒˆì˜ ê¸°ëŠ¥ë“¤ì„ ì„¤ëª…í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.",
                        "ì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹ì–´ë“¤ì„ ì•Œë ¤ë“œë¦¬ê² ìŠµë‹ˆë‹¤.",
                        "ë„ì›€ë§ì„ ì œê³µí•˜ê² ìŠµë‹ˆë‹¤."
                    ]
                },
                "greeting": {
                    "patterns": [
                        r".*ì•ˆë…•.*",
                        r".*hello.*",
                        r".*hi.*",
                        r".*ì¢‹ì€.*ì•„ì¹¨.*",
                        r".*ì¢‹ì€.*ì˜¤í›„.*",
                        r".*ì¢‹ì€.*ì €ë….*",
                        r".*ë°˜ê°€ì›Œ.*",
                        r".*ì†Œë¦¬ìƒˆ.*"
                    ],
                    "response_templates": [
                        "ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?",
                        "ë°˜ê°‘ìŠµë‹ˆë‹¤! ì–´ë–¤ ì‘ì—…ì„ í•˜ì‹œê² ì–´ìš”?",
                        "ì†Œë¦¬ìƒˆì…ë‹ˆë‹¤. ëª…ë ¹ì„ ë§ì”€í•´ì£¼ì„¸ìš”."
                    ]
                },
                "status": {
                    "patterns": [
                        r".*ìƒíƒœ.*í™•ì¸.*",
                        r".*ì–´ë–»ê²Œ.*ëŒì•„ê°€.*",
                        r".*ì‹œìŠ¤í…œ.*ìƒíƒœ.*",
                        r".*ì˜.*ë™ì‘.*",
                        r".*ë¬¸ì œ.*ì—†.*",
                        r".*ì •ìƒ.*ë™ì‘.*",
                        r".*status.*",
                        r".*health.*check.*"
                    ],
                    "response_templates": [
                        "ì‹œìŠ¤í…œì´ ì •ìƒì ìœ¼ë¡œ ë™ì‘í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
                        "ëª¨ë“  ê¸°ëŠ¥ì´ ì •ìƒì…ë‹ˆë‹¤.",
                        "ì†Œë¦¬ìƒˆê°€ ê±´ê°•í•˜ê²Œ ë™ì‘ ì¤‘ì…ë‹ˆë‹¤."
                    ]
                }
            },
            "context_patterns": {
                "positive_confirmation": [
                    r".*ë„¤.*", r".*ì˜ˆ.*", r".*ë§ì•„.*", r".*ì¢‹ì•„.*", 
                    r".*ê·¸ë˜.*", r".*ê³„ì†.*", r".*ì§„í–‰.*", r".*yes.*", r".*ok.*"
                ],
                "negative_confirmation": [
                    r".*ì•„ë‹ˆ.*", r".*ì‹«ì–´.*", r".*ì•ˆ.*í•´.*", r".*ì·¨ì†Œ.*", 
                    r".*ê·¸ë§Œ.*", r".*no.*", r".*cancel.*"
                ]
            }
        }
    
    def analyze_intent(self, text: str) -> Tuple[Optional[str], float, Optional[str]]:
        """ìì—°ì–´ í…ìŠ¤íŠ¸ì—ì„œ ì˜ë„(intent) ë¶„ì„"""
        text = text.lower().strip()
        best_intent = None
        best_score = 0.0
        matched_pattern = None
        
        # ê° ì˜ë„ë³„ë¡œ íŒ¨í„´ ë§¤ì¹­
        for intent, config in self.intent_patterns["intents"].items():
            for pattern in config["patterns"]:
                if re.search(pattern, text, re.IGNORECASE):
                    # íŒ¨í„´ì´ ë§¤ì¹­ë˜ë©´ ìœ ì‚¬ë„ ê³„ì‚°
                    similarity = self.calculate_similarity(text, pattern)
                    if similarity > best_score:
                        best_intent = intent
                        best_score = similarity
                        matched_pattern = pattern
        
        return best_intent, best_score, matched_pattern
    
    def calculate_similarity(self, text: str, pattern: str) -> float:
        """í…ìŠ¤íŠ¸ì™€ íŒ¨í„´ ê°„ì˜ ìœ ì‚¬ë„ ê³„ì‚°"""
        # ì •ê·œì‹ íŒ¨í„´ì—ì„œ íŠ¹ìˆ˜ë¬¸ì ì œê±°í•˜ì—¬ ìˆœìˆ˜ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        clean_pattern = re.sub(r'[.*\[\](){}\\|+?^$]', '', pattern)
        
        # ë‹¨ì–´ ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚°
        text_words = set(text.split())
        pattern_words = set(clean_pattern.split())
        
        if not pattern_words:
            return 0.5
        
        intersection = text_words.intersection(pattern_words)
        similarity = len(intersection) / len(pattern_words)
        
        # ì •í™•í•œ ë§¤ì¹­ì— ë³´ë„ˆìŠ¤ ì ìˆ˜
        if re.search(pattern, text, re.IGNORECASE):
            similarity += 0.3
        
        return min(similarity, 1.0)
    
    def generate_response(self, intent: str) -> str:
        """ì˜ë„ì— ë”°ë¥¸ ì‘ë‹µ ìƒì„±"""
        if intent in self.intent_patterns["intents"]:
            templates = self.intent_patterns["intents"][intent]["response_templates"]
            import random
            return random.choice(templates)
        return "ëª…ë ¹ì„ ì´í•´í–ˆìŠµë‹ˆë‹¤."
    
    def extract_entities(self, text: str, intent: str) -> Dict:
        """í…ìŠ¤íŠ¸ì—ì„œ ì—”í‹°í‹° ì¶”ì¶œ (íŒŒì¼ëª…, ì˜µì…˜ ë“±)"""
        entities = {}
        
        # íŒŒì¼ í™•ì¥ì íŒ¨í„´
        file_patterns = r'(\w+\.(py|js|html|css|json|txt|md))'
        files = re.findall(file_patterns, text, re.IGNORECASE)
        if files:
            entities['files'] = [match[0] for match in files]
        
        # ìˆ«ì íŒ¨í„´ (ë¼ì¸ ë²ˆí˜¸, ê°œìˆ˜ ë“±)
        numbers = re.findall(r'\b(\d+)\b', text)
        if numbers:
            entities['numbers'] = [int(num) for num in numbers]
        
        # íŠ¹ì • í‚¤ì›Œë“œ ì¶”ì¶œ
        if intent == "refactor":
            if re.search(r'í•¨ìˆ˜|function', text, re.IGNORECASE):
                entities['target'] = 'function'
            elif re.search(r'í´ë˜ìŠ¤|class', text, re.IGNORECASE):
                entities['target'] = 'class'
        
        return entities
    
    def process_natural_language(self, text: str) -> Dict:
        """ìì—°ì–´ í…ìŠ¤íŠ¸ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ì²˜ë¦¬"""
        # ì»¨í…ìŠ¤íŠ¸ì— ì¶”ê°€
        self.context_memory.append(text)
        if len(self.context_memory) > 5:  # ìµœê·¼ 5ê°œë§Œ ìœ ì§€
            self.context_memory.pop(0)
        
        # ì˜ë„ ë¶„ì„
        intent, confidence, pattern = self.analyze_intent(text)
        
        # ì—”í‹°í‹° ì¶”ì¶œ
        entities = self.extract_entities(text, intent) if intent else {}
        
        # ê°ì • ë¶„ì„
        emotion = self.analyze_emotion(text, intent)
        
        # ì‘ë‹µ ìƒì„±
        response = self.generate_response(intent) if intent else "ì£„ì†¡í•©ë‹ˆë‹¤. ëª…ë ¹ì„ ì´í•´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        
        return {
            "original_text": text,
            "intent": intent,
            "confidence": confidence,
            "matched_pattern": pattern,
            "entities": entities,
            "emotion": emotion,
            "response": response,
            "context": self.context_memory.copy()
        }
    
    def analyze_emotion(self, text: str, intent: str) -> str:
        """í…ìŠ¤íŠ¸ì™€ ì˜ë„ì—ì„œ ê°ì • ë¶„ì„"""
        text_lower = text.lower()
        
        # ê¸ì •ì  í‘œí˜„
        positive_patterns = [
            r'ì¢‹ì•„', r'ê°ì‚¬', r'ê³ ë§ˆì›Œ', r'í›Œë¥­', r'ì™„ë²½', r'ìµœê³ ', r'ë©‹ì ¸'
        ]
        
        # ë¶€ì •ì  í‘œí˜„  
        negative_patterns = [
            r'ì‹«ì–´', r'ì•ˆë¼', r'ë¬¸ì œ', r'ì˜¤ë¥˜', r'ì‹¤íŒ¨', r'ì•ˆì¢‹', r'ë‚˜ë¹ '
        ]
        
        # ê¸‰í•œ/í¥ë¶„ í‘œí˜„
        excited_patterns = [
            r'ë¹¨ë¦¬', r'ê¸‰í•´', r'ë‹¹ì¥', r'ì§€ê¸ˆ', r'!!!', r'!!'
        ]
        
        # íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ ê°ì • íŒë‹¨
        for pattern in excited_patterns:
            if re.search(pattern, text_lower):
                return "excited"
                
        for pattern in positive_patterns:
            if re.search(pattern, text_lower):
                return "happy"
                
        for pattern in negative_patterns:
            if re.search(pattern, text_lower):
                return "sad"
        
        # ì˜ë„ì— ë”°ë¥¸ ê¸°ë³¸ ê°ì •
        intent_emotions = {
            "greeting": "happy",
            "help": "friendly", 
            "stop": "neutral",
            "refactor": "success",
            "sync": "success",
            "test": "neutral",
            "build": "success",
            "status": "neutral"
        }
        
        return intent_emotions.get(intent, "neutral")
    
    def get_command_mapping(self, intent: str) -> Optional[str]:
        """ì˜ë„ë¥¼ ì‹¤ì œ ëª…ë ¹ì–´ë¡œ ë§¤í•‘"""
        mapping = {
            "refactor": "ë¦¬íŒ©í„°ë§",
            "sync": "ë™ê¸°í™”", 
            "stop": "ì¢…ë£Œ",
            "help": "ë„ì›€ë§",
            "greeting": "ì¸ì‚¬",
            "status": "ìƒíƒœ",
            "test": "í…ŒìŠ¤íŠ¸",
            "build": "ë¹Œë“œ"
        }
        return mapping.get(intent)
    
    def add_pattern(self, intent: str, pattern: str):
        """ìƒˆë¡œìš´ íŒ¨í„´ ì¶”ê°€"""
        if intent not in self.intent_patterns["intents"]:
            self.intent_patterns["intents"][intent] = {
                "patterns": [],
                "response_templates": ["ëª…ë ¹ì„ ì‹¤í–‰í•˜ê² ìŠµë‹ˆë‹¤."]
            }
        
        self.intent_patterns["intents"][intent]["patterns"].append(pattern)
        self.save_patterns(self.intent_patterns)
    
    def learn_from_feedback(self, text: str, correct_intent: str):
        """ì‚¬ìš©ì í”¼ë“œë°±ìœ¼ë¡œë¶€í„° í•™ìŠµ"""
        # ê°„ë‹¨í•œ í•™ìŠµ ë©”ì»¤ë‹ˆì¦˜ - ì„±ê³µí•œ íŒ¨í„´ì„ ê¸°ë¡
        pattern = f".*{re.escape(text.lower())}.*"
        self.add_pattern(correct_intent, pattern)
        print(f"ğŸ“š í•™ìŠµ ì™„ë£Œ: '{text}' -> '{correct_intent}'")